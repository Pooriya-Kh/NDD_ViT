{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84422c53-a127-4767-8ea5-9c8282b6fab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "# Accessing moduels\n",
    "import sys,os\n",
    "sys.path.append(os.path.realpath('../Modules'))\n",
    "\n",
    "from dataloader.dataset import ADNI3Channels\n",
    "from dataloader.dataloader import ADNILoader\n",
    "from dataloader.transforms import Transforms\n",
    "\n",
    "from model.model import ViT\n",
    "from model.train import Trainer\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "# from utils.report import sklearn_classification_report, custom_classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b159d54-7226-401c-816f-f83ee5783bff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dataset and Dataloader Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b11b43-41e4-4f42-bde8-545efc2429bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"CN\", 1: \"MCI\", 2: \"AD\"}\n",
    "label2id = {\"CN\": 0, \"MCI\": 1, \"AD\": 2}\n",
    "\n",
    "transforms = Transforms(image_size=(384, 384), p=0.5)\n",
    "\n",
    "train_ds = ADNI3Channels(\"../Data/Training/\", transforms=transforms.train())\n",
    "valid_ds = ADNI3Channels(\"../Data/Validation/\", transforms=transforms.eval())\n",
    "test_ds = ADNI3Channels(\"../Data/Test/\", transforms=transforms.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be4e16a-ec1c-4e73-ba2f-6cc086513e4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image, label = train_ds[0]\n",
    "\n",
    "print(\"Image shape:\", image.shape)\n",
    "print(\"Label:\", id2label[label.item()], \"\\n\")\n",
    "\n",
    "print(\"Number of training samples:\", len(train_ds))\n",
    "print(\"Number of validation samples:\", len(valid_ds))\n",
    "print(\"Number of test samples:\", len(test_ds), \"\\n\")\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(6, 2), dpi=300)\n",
    "for i in range(3):\n",
    "    axes[i].imshow(image[i, :, :])\n",
    "    axes[i].axis(\"off\");\n",
    "\n",
    "print(\"Min pixel value =\", image.min().item())\n",
    "print(\"Max pixel value =\", image.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f342a0-b447-4fb1-9f2d-f31478574b84",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "kwargs = {'train_ds': train_ds,\n",
    "           'valid_ds': valid_ds,\n",
    "           'test_ds': test_ds,\n",
    "         }\n",
    "\n",
    "train_dataloader = ADNILoader(**kwargs).train_dataloader()\n",
    "valid_dataloader= ADNILoader(**kwargs).validation_dataloader()\n",
    "test_dataloader = ADNILoader(**kwargs).test_dataloader()\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "print(batch[0].shape)\n",
    "print(batch[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed18ae1-e86b-4e18-a833-fd2abe0dfdcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae6da4e-8b63-4387-9785-b2d6378d8a4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ViT(\n",
    "    pretrained=True,\n",
    "    model_name=\"google/vit-base-patch32-384\",\n",
    "    device=\"cuda:1\"\n",
    ")\n",
    "\n",
    "kwargs = {\n",
    "    \"epochs\": 100,\n",
    "    \"model\":model,\n",
    "    \"train_dataloader\": train_dataloader,\n",
    "    \"valid_dataloader\": valid_dataloader,\n",
    "    \"test_dataloader\": test_dataloader,\n",
    "}\n",
    "\n",
    "trainer = Trainer(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c8a12f-48be-42c1-985b-ad3394ea2289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559633bf-b6c1-4f2c-847b-da4042ffb883",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Save and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb97c16-bad5-4b6e-9a99-b3abafccbe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_best_state(\"acc\")\n",
    "# model.save_best_state_file(\"acc\", \"Best models/\", \"ViT_Pretrained\")\n",
    "model.load_best_state_file(\"acc\", \"Best models/\", \"ViT_Pretrained\")\n",
    "train_ds.transforms = transforms.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67006c7-4308-44eb-8aca-376c641c7409",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586ffc97-b9a1-4caf-aceb-e1a0fc86c204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.test(trainer.train_dataloader)\n",
    "# trainer.test(trainer.valid_dataloader)\n",
    "trainer.test(trainer.test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ae7cff-da8a-4e5d-8a04-a404d9bee240",
   "metadata": {},
   "source": [
    "# 95% CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2353da-bead-44f2-94c7-34a60b3fa37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchmetrics.classification import MulticlassF1Score, MulticlassAccuracy\n",
    "import torch\n",
    "\n",
    "# metric = MulticlassF1Score(num_classes=3, average=None)\n",
    "metric = MulticlassAccuracy(num_classes=3, average=None)\n",
    "\n",
    "# indices = range(0, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1500effe-336d-474c-86c7-d49ef86e48d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = []\n",
    "\n",
    "for itr in range(1000):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    indices = np.random.randint(0, len(test_ds), len(test_ds))\n",
    "    \n",
    "    for i in indices:\n",
    "        x, y = test_ds[i]\n",
    "        y_true.append(y.item())\n",
    "    \n",
    "        logits, _, _ = model(x)\n",
    "        y_pred.append(logits.argmax(1).cpu().item())\n",
    "    \n",
    "    y_true = torch.tensor(y_true)\n",
    "    y_pred = torch.tensor(y_pred)\n",
    "\n",
    "    metric_value = metric(y_pred, y_true)\n",
    "    metrics.append(metric_value)\n",
    "    print(f\"{itr}: {metric_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de27b001-729b-435d-960a-4e6913455237",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_tensor = torch.stack(metrics)\n",
    "print(metric_tensor)\n",
    "\n",
    "# torch.save(metric_tensor, \"accuracy_tensor.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa40564-f0ab-438f-8c8d-e714dfa92acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (torch.load(\"accuracy_tensor.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1eb3ed-4648-4876-aef9-67d0cc18ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "CN_tensor = metric_tensor[:, 0].numpy()\n",
    "MCI_tensor = metric_tensor[:, 1].numpy()\n",
    "AD_tensor = metric_tensor[:, 2].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f3d838-3156-491b-84b2-6405b0c939b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CN  -> {np.mean(CN_tensor)}: {np.percentile(CN_tensor, 2.5)}, {np.percentile(CN_tensor, 97.5)}\")\n",
    "print(f\"MCI -> {np.mean(MCI_tensor)}: {np.percentile(MCI_tensor, 2.5)}, {np.percentile(MCI_tensor, 97.5)}\")\n",
    "print(f\"AD  -> {np.mean(AD_tensor)}: {np.percentile(AD_tensor, 2.5)}, {np.percentile(AD_tensor, 97.5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fc6798-1f9e-407d-91c6-611ea7c02390",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1s = (torch.sum(metric_tensor, dim=1) / 3).numpy()\n",
    "print(f\"Whole  -> {np.mean(f1s)}: {np.percentile(f1s, 2.5)}, {np.percentile(f1s, 97.5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9472055d-1958-42ac-8a53-2be65bf699ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
