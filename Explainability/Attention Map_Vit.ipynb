{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb5cbf8-9d6d-4f73-805c-0c351ce06900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "# Accessing moduels\n",
    "import sys,os\n",
    "sys.path.append(os.path.realpath('../Modules'))\n",
    "\n",
    "from dataloader.dataset import ADNI3Channels\n",
    "from dataloader.dataloader import ADNILoader\n",
    "from dataloader.transforms import Transforms\n",
    "\n",
    "from model.model import ViT\n",
    "from model.train import Trainer\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde51da3-52fd-4e48-a361-2591941827f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "# import torch.nn as nn\n",
    "# from torchvision.transforms import Compose, Resize\n",
    "from atlas.atlas import AAL3Channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b159d54-7226-401c-816f-f83ee5783bff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dataset and Dataloader Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7ce338-184d-4378-a7da-d22ff6723aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"CN\", 1: \"MCI\", 2: \"AD\"}\n",
    "label2id = {\"CN\": 0, \"MCI\": 1, \"AD\": 2}\n",
    "\n",
    "transforms = Transforms(image_size=(384, 384), p=0.5)\n",
    "\n",
    "train_ds = ADNI3Channels(\"../Data/Training/\", transforms=transforms.eval())\n",
    "valid_ds = ADNI3Channels(\"../Data/Validation/\", transforms=transforms.eval())\n",
    "test_ds = ADNI3Channels(\"../Data/Test/\", transforms=transforms.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be4e16a-ec1c-4e73-ba2f-6cc086513e4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image, label = train_ds[0]\n",
    "\n",
    "print(\"Image shape:\", image.shape)\n",
    "print(\"Label:\", id2label[label.item()], \"\\n\")\n",
    "\n",
    "print(\"Number of training samples:\", len(train_ds))\n",
    "print(\"Number of validation samples:\", len(valid_ds))\n",
    "print(\"Number of test samples:\", len(test_ds), \"\\n\")\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(6, 2), dpi=300)\n",
    "for i in range(3):\n",
    "    axes[i].imshow(image[i, :, :])\n",
    "    axes[i].axis(\"off\");\n",
    "\n",
    "print(\"Min pixel value =\", image.min().item())\n",
    "print(\"Max pixel value =\", image.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f342a0-b447-4fb1-9f2d-f31478574b84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kwargs = {'train_ds': train_ds,\n",
    "           'valid_ds': valid_ds,\n",
    "           'test_ds': test_ds,\n",
    "         }\n",
    "\n",
    "train_dataloader = ADNILoader(**kwargs).train_dataloader()\n",
    "valid_dataloader= ADNILoader(**kwargs).validation_dataloader()\n",
    "test_dataloader = ADNILoader(**kwargs).test_dataloader()\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "print(batch[0].shape)\n",
    "print(batch[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed18ae1-e86b-4e18-a833-fd2abe0dfdcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87cab3b-b09d-4d5d-b77a-0fe10cff670f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ViT(\n",
    "    pretrained=True,\n",
    "    model_name=\"google/vit-base-patch32-384\",\n",
    "    device=\"cuda:0\"\n",
    ")\n",
    "\n",
    "model.load_best_state_file(\"acc\", \"../ViT/Best models/\", \"ViT_Pretrained\")\n",
    "\n",
    "kwargs = {\n",
    "    \"epochs\": 100,\n",
    "    \"model\":model,\n",
    "    \"train_dataloader\": train_dataloader,\n",
    "    \"valid_dataloader\": valid_dataloader,\n",
    "    \"test_dataloader\": test_dataloader,\n",
    "}\n",
    "\n",
    "trainer = Trainer(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81460884-3eb8-4ebd-a224-1b4f6857e319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.test(trainer.train_dataloader)\n",
    "# trainer.test(trainer.valid_dataloader)\n",
    "trainer.test(trainer.test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e911cb8-890d-4f08-98b1-3196665552d8",
   "metadata": {},
   "source": [
    "# Getting Attention Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483aeba3-d45f-489e-8e5a-fdd809189bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.attention import get_attention_map\n",
    "\n",
    "idx = 10\n",
    "image, label = test_ds[idx]\n",
    "# It's possible to modify dataloader class to get batch size of 1 instead of unsqueeze\n",
    "logits, attention, _ = model(image.unsqueeze(0).to(model.device))\n",
    "print(\"Label:\", id2label[label.item()])\n",
    "print(\"Prediction:\", id2label[torch.argmax(logits).item()])\n",
    "img, att_map = get_attention_map(image, attention, model.device, rotate=True)\n",
    "\n",
    "# Mask\n",
    "image = image.permute(1, 2, 0).numpy()\n",
    "image = np.rot90(image)\n",
    "img = img * np.where(image>0, 1, 0)\n",
    "img = img [:, :, 2]\n",
    "\n",
    "# Normalize\n",
    "img = (img - img.min()) / (img.max() - img.min())\n",
    "\n",
    "fig, ax = plt.subplots(dpi=300)\n",
    "im = ax.imshow(img, cmap='plasma')\n",
    "im = ax.imshow(img)\n",
    "ax.axis(\"off\");\n",
    "cbar = fig.colorbar(im);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3491b0e0-d8fa-4921-b6f2-f241a597035d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
